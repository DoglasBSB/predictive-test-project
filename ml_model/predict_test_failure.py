import numpy as np
import pandas as pd
import tensorflow as tf
import joblib
import os

# Caminhos dos arquivos
MODEL_PATH = "lstm_model.h5"  # Alterado para o nome correto do modelo treinado
SCALER_PATH = "scaler.pkl"
TEST_DATA_PATH = "test_data.csv"  # Atualizado para corresponder ao arquivo gerado

# Verifica se o arquivo de dados existe antes de tentar carregar
if not os.path.exists(TEST_DATA_PATH):
    print("âš ï¸ Arquivo test_data.csv nÃ£o encontrado! Usando valores padrÃ£o.")
    new_test_data = np.array([[0, 0, 0]])  # Valores padrÃ£o para evitar erro
else:
    
    # Carregar os dados reais mais recentes para previsÃ£o
    df = pd.read_csv(TEST_DATA_PATH)

    # Selecionar apenas as colunas usadas no treinamento do modelo
# Aqui, ajustamos para 'failed_tests' e 'response_time' (apenas 2 caracterÃ­sticas)
feature_columns = ['failed_tests', 'response_time']  # Certifique-se de que sÃ£o 2 caracterÃ­sticas
new_test_data = df[feature_columns].iloc[-1:].values

# Carregar o scaler salvo durante o treinamento
if not os.path.exists(SCALER_PATH):
    print("âš ï¸ Arquivo scaler.pkl nÃ£o encontrado! NormalizaÃ§Ã£o pode estar incorreta.")
    scaler = None
else:
    scaler = joblib.load(SCALER_PATH)
    new_test_data = scaler.transform(new_test_data)  # ğŸš€ Agora com as colunas corretas

# Reshape para o formato esperado pelo LSTM
new_test_data = new_test_data.reshape((1, 1, new_test_data.shape[1]))

# Carregar modelo treinado
if not os.path.exists(MODEL_PATH):
    print("âŒ Modelo nÃ£o encontrado! Certifique-se de que o treinamento foi realizado.")
else:
    model = tf.keras.models.load_model(MODEL_PATH, compile=False)

    # Fazer previsÃ£o
    prediction = model.predict(new_test_data)
    probability = prediction[0][0]

    print(f"ğŸ”® Probabilidade de falha: {probability:.2f}")

    if probability > 0.5:
        print("ğŸ”¥ Alta chance de falha!")
    else:
        print("âœ… Baixa chance de falha. Teste nÃ£o necessÃ¡rio.")
